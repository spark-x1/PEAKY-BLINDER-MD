

const axios = require("axios");
const { lee } = require("../lee");

lee({
    pattern: "lee",
    alias: "lee",
    desc: "Interact with ChatGPT using the XD Api.",
    category: "ai",
    react: "ğŸ¤–",
    use: ".lee <your query>",
    filename: __filename,
}, async (conn, mek, m, { from, args, q, reply }) => {
    try {
        // VÃ©rification de l'entrÃ©e utilisateur
        if (!q) return reply("âš ï¸ Please provide a query for lee Ai.\n\nExample:\n.lee What is AI?");

        // Utilisation de `${text}` dans le endpoint API
        const text = q;  // Texte de la requÃªte de l'utilisateur
        const encodedText = encodeURIComponent(text);  // S'assurer que le texte est encodÃ© correctement

        const url = `https://api.dreaded.site/api/chatgpt?text=${encodedText}`;

        console.log('Requesting URL:', url);  // Afficher l'URL pour vÃ©rifier

        // Appel Ã  l'API avec headers personnalisÃ©s (ajoute des headers si nÃ©cessaire)
        const response = await axios.get(url, {
            headers: {
                'User-Agent': 'Mozilla/5.0',  // Ajouter un User-Agent pour simuler une requÃªte valide
                'Accept': 'application/json',  // SpÃ©cifier que l'on attend une rÃ©ponse JSON
            }
        });

        // DÃ©boguer et afficher la rÃ©ponse complÃ¨te
        console.log('Full API Response:', response.data);

        // VÃ©rification de la structure de la rÃ©ponse
        if (!response || !response.data || !response.data.result) {
            return reply("âŒ No response received from the Malvin API. Please try again later.");
        }

        // Extraire uniquement le texte de la rÃ©ponse (le prompt)
        const gptResponse = response.data.result.prompt;

        if (!gptResponse) {
            return reply("âŒ The API returned an unexpected format. Please try again later.");
        }

        // Image AI Ã  envoyer
        const ALIVE_IMG = 'https://files.catbox.moe/79tf9z.jpg'; // Remplacez par l'URL de votre image AI

        // LÃ©gende avec des informations formatÃ©es
        const formattedInfo = `ğŸ¤– *Malvin's Response:*\n\n${gptResponse}`;

        // Envoyer le message avec image et lÃ©gende
        await conn.sendMessage(from, {
            image: { url: ALIVE_IMG }, // Assurez-vous que l'URL est valide
            caption: formattedInfo,
            contextInfo: { 
                mentionedJid: [m.sender],
                forwardingScore: 999,
                isForwarded: true,
                forwardedNewsletterMessageInfo: {
                    newsletterJid: '120363403627964616@newsletter',
                    newsletterName: '*PEAKY-BLINDER-MD*',
                    serverMessageId: 143
                }
            }
        }, { quoted: mek });

    } catch (error) {
        console.error("Error in GPT command:", error);

        // Affichage du message d'erreur dans la console pour plus de dÃ©tails
        if (error.response) {
            console.log("Error Response Data:", error.response.data);
        } else {
            console.log("Error Details:", error.message);
        }

        // RÃ©pondre avec des dÃ©tails de l'erreur
        const errorMessage = `
âŒ An error occurred while processing the GPT command.
ğŸ›  *Error Details*:
${error.message}

Please report this issue or try again later.
        `.trim();
        return reply(errorMessage);
    }
});
lee({
    pattern: "llama3",
    desc: "Get a response from Llama3 AI using the provided prompt.",
    category: "ai",
    react: "ğŸ¤–",
    filename: __filename,
    use: ".llama3 <your prompt>"
}, async (conn, mek, m, { from, q, reply }) => {
    try {
        // Check if a prompt is provided by the user
        if (!q) return reply("âš ï¸ Please provide a prompt for Llama3 AI.");

        // Inform the user that the request is being processed
        await reply("> *Processing your prompt...*");

        // API URL with encoded user prompt
        const apiUrl = `https://api.davidcyriltech.my.id/ai/llama3?text=${encodeURIComponent(q)}`;

        // Send a GET request to the API
        const response = await axios.get(apiUrl);
        console.log("Llama3 API Response:", response.data);

        // Extract AI response
        let llamaResponse;
        if (typeof response.data === "string") {
            llamaResponse = response.data.trim();
        } else if (typeof response.data === "object") {
            llamaResponse = response.data.response || response.data.result || JSON.stringify(response.data);
        } else {
            llamaResponse = "Unable to process the AI response.";
        }

        // AI image to attach
        const AI_IMG = 'https://files.catbox.moe/gqsf1j.jpg'; // Replace with a valid image URL

        // Formatted response text
        const formattedInfo = `ğŸ¤– *Llama3 Response:*\n\n${llamaResponse}`;

        // Send the response with an image
        await conn.sendMessage(from, {
            image: { url: ALIVE_IMG }, // Ensure the URL is valid
            caption: formattedInfo,
            contextInfo: { 
                mentionedJid: [m.sender],
                forwardingScore: 999,
                isForwarded: true,
                forwardedNewsletterMessageInfo: {
                    newsletterJid: '120363403627964616@newsletter',
                    newsletterName: 'ğ‘·ğ‘¬ğ‘¨ğ‘²ğ’€-ğ‘©ğ‘³ğ‘°ğ‘µğ‘«ğ‘¬ğ‘¹-ğ‘´ğ‘« ğ€ğˆ',
                    serverMessageId: 143
                }
            }
        }, { quoted: mek });

    } catch (error) {
        console.error("Error in llama3 command:", error);
        return reply(`âŒ An error occurred: ${error.message}`);
    }
});